{"cells":[{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# !pip install transformers datasets\n","# !pip install torch torchvision"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["# https://huggingface.co/docs/api-inference/index\n","\n","api_key_hf = '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'"]},{"cell_type":"markdown","metadata":{},"source":["<br>\n","\n","# Python"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/Users/macbookdealejandro/anaconda3/envs/thebridge_desafio/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n","No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n","Using a pipeline without specifying a model name and revision in production is not recommended.\n","Downloading (‚Ä¶)lve/main/config.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 629/629 [00:00<00:00, 59.1kB/s]\n","Downloading model.safetensors: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 268M/268M [00:25<00:00, 10.4MB/s] \n","Downloading (‚Ä¶)okenizer_config.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48.0/48.0 [00:00<00:00, 7.99kB/s]\n","Downloading (‚Ä¶)solve/main/vocab.txt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 232k/232k [00:00<00:00, 1.08MB/s]\n"]}],"source":["# It will download a model (~268MB)\n","\n","from transformers import pipeline\n","\n","classifier = pipeline(\"sentiment-analysis\")"]},{"cell_type":"markdown","metadata":{},"source":["<br>\n","\n","### --> English"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["label: POSITIVE, with score: 0.9998\n","label: NEGATIVE, with score: 0.5309\n"]}],"source":["results = classifier([\"We are very happy to show you the ü§ó Transformers library.\", \"We hope you don't hate it.\"])\n","for result in results:\n","    print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")"]},{"cell_type":"markdown","metadata":{},"source":["<br>\n","\n","### --> Spanish\n","\n","it does not work well"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Etiqueta: NEGATIVE, con puntuaci√≥n: 0.6758\n","Etiqueta: NEGATIVE, con puntuaci√≥n: 0.7361\n"]}],"source":["results = classifier([\"Estamos muy felices de verte.\", \"Espero no lo est√©s pasando mal.\"])\n","for result in results:\n","    print(f\"Etiqueta: {result['label']}, con puntuaci√≥n: {round(result['score'], 4)}\")"]},{"cell_type":"markdown","metadata":{},"source":["<br>\n","\n","# PyTorch"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\""]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading (‚Ä¶)lve/main/config.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 953/953 [00:00<00:00, 161kB/s]\n","Downloading pytorch_model.bin: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 669M/669M [01:11<00:00, 9.33MB/s] \n","Downloading (‚Ä¶)okenizer_config.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 39.0/39.0 [00:00<00:00, 5.68kB/s]\n","Downloading (‚Ä¶)solve/main/vocab.txt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 872k/872k [00:00<00:00, 2.10MB/s]\n","Downloading (‚Ä¶)cial_tokens_map.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 112/112 [00:00<00:00, 38.8kB/s]\n"]}],"source":["# It will download a model (~600mb)\n","\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","\n","model = AutoModelForSequenceClassification.from_pretrained(model_name)\n","tokenizer = AutoTokenizer.from_pretrained(model_name)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)"]},{"cell_type":"markdown","metadata":{},"source":["<br>\n","\n","### --> Affirmative"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["{'label': '5 stars', 'score': 0.664089560508728}\n","{'label': '5 stars', 'score': 0.8077584505081177}\n"]}],"source":["list_ = [\n","    \"Nous sommes tr√®s heureux de vous pr√©senter la biblioth√®que ü§ó Transformers\",\n","    \"Estamos encantados de presentar la biblioteca ü§ó Transformers\"\n","]\n","\n","for result in list_:\n","    print(classifier(result)[0])"]},{"cell_type":"markdown","metadata":{},"source":["<br>\n","\n","### ---> Neutral / Negative"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["{'label': '3 stars', 'score': 0.2251354455947876}\n","{'label': '1 star', 'score': 0.6905421614646912}\n"]}],"source":["list_ = [\n","    \"Dire au revoir √† l'√©quipe avant de partir\",\n","    \"Desp√≠dete del equipo antes de marchar\"\n","]\n","\n","for result in list_:\n","    print(classifier(result)[0])"]},{"cell_type":"markdown","metadata":{},"source":["<br>\n","\n","### --> Very Negative"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["{'label': '5 stars', 'score': 0.4650614857673645}\n","{'label': '1 star', 'score': 0.24440932273864746}\n"]}],"source":["list_ = [\n","    \"Ton cousin est un fils de pute\",\n","    \"Tu primo es un hijo de puta\"\n","]\n","\n","for result in list_:\n","    print(classifier(result)[0])"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["{'label': '1 star', 'score': 0.7261529564857483}\n","{'label': '1 star', 'score': 0.8633244037628174}\n"]}],"source":["list_ = [\n","    \"Pourquoi √™tes-vous si inutile?\",\n","    \"¬øPor qu√© eres tan in√∫til?\"\n","]\n","\n","for result in list_:\n","    print(classifier(result)[0])"]},{"cell_type":"markdown","metadata":{},"source":["<br>\n","\n","# With DeepL"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["# !pip install --upgrade deepl\n","\n","# https://github.com/DeepLcom/deepl-python      # How to use"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["import deepl\n","\n","auth_key = \"cc5220b1-f22d-8f47-aa4d-28ee63b26314:fx\"  # Replace with your key\n","translator = deepl.Translator(auth_key)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Bonjour √† tous !\n","EN\n"]}],"source":["result = translator.translate_text(\"Hello, world!\", target_lang=\"FR\", formality=\"more\")\n","print(result.text)  # \"Bonjour, le monde !\"\n","print(result.detected_source_lang)  # \"EN\""]},{"cell_type":"markdown","metadata":{},"source":["<br>\n","\n","### --> Language detection before translation"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["I really enjoyed the event very much. It was very interesting to listen to the speakers.\n","ES\n","The event was disastrous. The facilities were awful and the air conditioning was very noisy.\n","ES\n"]}],"source":["POS_comment = \"La verdad es que el evento me gust√≥ much√≠simo. Fue muy interesante escuchar a los ponentes.\"\n","NEG_comment = \"El evento ha sido desastroso. Las instalaciones eran horribles y el aire acondicionado hac√≠a mucho ruido.\"\n","\n","comments = []\n","\n","for comment in [POS_comment, NEG_comment]:\n","    translation = translator.translate_text(comment, target_lang=\"EN-GB\")\n","    comments.append(translation.text)\n","    print(translation.text)\n","    print(translation.detected_source_lang)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/plain":["['I really enjoyed the event very much. It was very interesting to listen to the speakers.',\n"," 'The event was disastrous. The facilities were awful and the air conditioning was very noisy.']"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["comments"]},{"cell_type":"markdown","metadata":{},"source":["<br>\n","\n","### --> Using HuggingFace Pipeline"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n","Using a pipeline without specifying a model name and revision in production is not recommended.\n"]}],"source":["classifier = pipeline(\"sentiment-analysis\")"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["label: POSITIVE, with score: 0.9999\n","label: NEGATIVE, with score: 0.9998\n"]}],"source":["comm = classifier(comments)   # It is a list (with translations from DeepL)\n","\n","for comment in comm:\n","    print(f\"label: {comment['label']}, with score: {round(comment['score'], 4)}\")"]},{"cell_type":"markdown","metadata":{},"source":["<br>\n","\n","### --> Using HuggingFace Pipeline (with PyTorch)"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\""]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[],"source":["from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","\n","model = AutoModelForSequenceClassification.from_pretrained(model_name)\n","tokenizer = AutoTokenizer.from_pretrained(model_name)"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[{'label': '5 stars', 'score': 0.569577157497406}]\n","[{'label': '1 star', 'score': 0.6721544861793518}]\n"]}],"source":["classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n","\n","for comment in comments:\n","    print(classifier(comment))"]},{"cell_type":"markdown","metadata":{},"source":["<br>\n","\n","### --> Using HuggingFace Pipeline (community model)"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting sentencepiece\n","  Using cached sentencepiece-0.1.99-cp39-cp39-macosx_10_9_x86_64.whl (1.2 MB)\n","Installing collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.99\n"]}],"source":["# !pip install sentencepiece"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/Users/macbookdealejandro/anaconda3/envs/thebridge_desafio/lib/python3.9/site-packages/transformers/models/marian/tokenization_marian.py:194: UserWarning: Recommended: pip install sacremoses.\n","  warnings.warn(\"Recommended: pip install sacremoses.\")\n"]}],"source":["# It will download a model (310MB)\n","\n","from transformers import pipeline\n","\n","pipe = pipeline(\"translation\", model=\"salesken/translation-spanish-and-portuguese-to-english\")\n"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"text/plain":["[{'translation_text': 'The fact is that I enjoyed the event very much, and it was very interesting to listen to the rapporteurs.'},\n"," {'translation_text': 'The event has been disastrous, and the facilities were awful and the air conditioning made a lot of noise.'}]"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["pipe([POS_comment, NEG_comment])"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["The fact is that I enjoyed the event very much, and it was very interesting to listen to the rapporteurs.\n","The event has been disastrous, and the facilities were awful and the air conditioning made a lot of noise.\n"]}],"source":["comm = pipe([POS_comment, NEG_comment])   # It is a list (with translations from DeepL)\n","\n","for comment in comm:\n","    print(comment['translation_text'])"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"text/plain":["['I really enjoyed the event very much. It was very interesting to listen to the speakers.',\n"," 'The event was disastrous. The facilities were awful and the air conditioning was very noisy.']"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["# List with DeepL translations\n","\n","comments"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["# API\n","\n","import requests\n","\n","API_URL = \"https://api-inference.huggingface.co/models/salesken/translation-spanish-and-portuguese-to-english\"\n","headers = {\"Authorization\": \"Bearer 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\"}\n","\n","def query(payload):\n","\tresponse = requests.post(API_URL, headers=headers, json=payload)\n","\treturn response.json()\n","\t\n","output = query({\n","\t\"inputs\": \"–ú–µ–Ω—è –∑–æ–≤—É—Ç –í–æ–ª—å—Ñ–≥–∞–Ω–≥ –∏ —è –∂–∏–≤—É –≤ –ë–µ—Ä–ª–∏–Ω–µ\",\n","})"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"data":{"text/plain":["{'error': 'Model salesken/translation-spanish-and-portuguese-to-english is currently loading',\n"," 'estimated_time': 20.0}"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["output"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"data":{"text/plain":["'My name is Wolfgang and I live in Berlin.'"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["deepl_trans = translator.translate_text('–ú–µ–Ω—è –∑–æ–≤—É—Ç –í–æ–ª—å—Ñ–≥–∞–Ω–≥ –∏ —è –∂–∏–≤—É –≤ –ë–µ—Ä–ª–∏–Ω–µ', target_lang=\"EN-GB\")\n","deepl_trans.text"]},{"cell_type":"markdown","metadata":{},"source":["<br>\n","\n","<div style='color:red'><H1>DELETE CACHE AND MODELS</H1></div>"]},{"cell_type":"markdown","metadata":{},"source":["<div style='color:red'><H3>--> Show and delete the cache</H3></div>\n","\n","1. Open a Terminal\n","2. Enter your virtual env\n","3. This code shows the cache:\n","\n","    ```python\n","    conda clean --all --dry-run\n","    ```\n","4. This code deletes the cache:\n","\n","    ```python\n","    conda clean --all\n","    ```\n","\n","<br><br>\n","\n","<div style='color:red'><H3>--> View the size of downloaded Hugging Face models in your environment on Mac/Linux</H3></div>\n","\n","1. Open a Terminal\n","2. Enter your virtual env\n","3. Navigate to the location where Hugging Face stores downloaded models:\n","\n","    ```python\n","    cd ~/.cache/huggingface/\n","    ```\n","    \n","4. Once inside the folder, you can use the du (disk usage) command to see the total size of the folder and all downloaded models:\n","\n","    ```python\n","    du -sh *\n","    ```\n","    \n","5. Go back to the Cach√© folder and delete the HuggingFace folder:\n","\n","    ```python\n","    cd ..   # to go back to the cache folder\n","\n","    ls      # to view folders in cache folder\n","\n","    rm -rf huggingface  # to delete folder\n","    ```\n","\n","<br><br>\n","\n","<div style='color:red'><H3>--> View the size of downloaded Hugging Face models in your environment on Windows</H3></div>\n","\n","1. Open File Explorer.\n","2. Navigate to the location where Hugging Face stores the downloaded models. This is usually located in ```C:\\Users\\YourUser\\.cache\\huggingface\\```. You can copy and paste this path into your File Explorer address bar.\n","Once inside the folder, you can view the size of each model and the entire folder by selecting the models and right-clicking on them. Then select \"Properties\" from the context menu."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"thebridge_desaf√≠o","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
