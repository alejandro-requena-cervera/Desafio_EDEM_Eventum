{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Obtaining dependency information for openai from https://files.pythonhosted.org/packages/ae/59/911d6e5f1d7514d79c527067643376cddcf4cb8d1728e599b3b03ab51c69/openai-0.28.0-py3-none-any.whl.metadata\n",
      "  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting requests>=2.20 (from openai)\n",
      "  Obtaining dependency information for requests>=2.20 from https://files.pythonhosted.org/packages/70/8e/0e2d847013cb52cd35b38c009bb167a1a26b2ce6cd6965bf26b47bc0bf44/requests-2.31.0-py3-none-any.whl.metadata\n",
      "  Using cached requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tqdm (from openai)\n",
      "  Obtaining dependency information for tqdm from https://files.pythonhosted.org/packages/00/e5/f12a80907d0884e6dff9c16d0c0114d81b8cd07dc3ae54c5e962cc83037e/tqdm-4.66.1-py3-none-any.whl.metadata\n",
      "  Downloading tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m784.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting aiohttp (from openai)\n",
      "  Obtaining dependency information for aiohttp from https://files.pythonhosted.org/packages/e6/9c/41d1c23c9e2dfc4cc0bd295754539f186fd012460b8b4ec091e42d3dbcc2/aiohttp-3.8.5-cp39-cp39-macosx_10_9_x86_64.whl.metadata\n",
      "  Using cached aiohttp-3.8.5-cp39-cp39-macosx_10_9_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests>=2.20->openai)\n",
      "  Obtaining dependency information for charset-normalizer<4,>=2 from https://files.pythonhosted.org/packages/7b/c6/7f75892d87d7afcf8ed909f3e74de1bc61abd9d77cd9aab1f449430856c5/charset_normalizer-3.2.0-cp39-cp39-macosx_10_9_x86_64.whl.metadata\n",
      "  Using cached charset_normalizer-3.2.0-cp39-cp39-macosx_10_9_x86_64.whl.metadata (31 kB)\n",
      "Collecting idna<4,>=2.5 (from requests>=2.20->openai)\n",
      "  Using cached idna-3.4-py3-none-any.whl (61 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.20->openai)\n",
      "  Obtaining dependency information for urllib3<3,>=1.21.1 from https://files.pythonhosted.org/packages/37/dc/399e63f5d1d96bb643404ee830657f4dfcf8503f5ba8fa3c6d465d0c57fe/urllib3-2.0.5-py3-none-any.whl.metadata\n",
      "  Using cached urllib3-2.0.5-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests>=2.20->openai)\n",
      "  Obtaining dependency information for certifi>=2017.4.17 from https://files.pythonhosted.org/packages/4c/dd/2234eab22353ffc7d94e8d13177aaa050113286e93e7b40eae01fbf7c3d9/certifi-2023.7.22-py3-none-any.whl.metadata\n",
      "  Using cached certifi-2023.7.22-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp->openai)\n",
      "  Using cached attrs-23.1.0-py3-none-any.whl (61 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->openai)\n",
      "  Using cached multidict-6.0.4-cp39-cp39-macosx_10_9_x86_64.whl (29 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->openai)\n",
      "  Obtaining dependency information for async-timeout<5.0,>=4.0.0a3 from https://files.pythonhosted.org/packages/a7/fa/e01228c2938de91d47b307831c62ab9e4001e747789d0b05baf779a6488c/async_timeout-4.0.3-py3-none-any.whl.metadata\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->openai)\n",
      "  Using cached yarl-1.9.2-cp39-cp39-macosx_10_9_x86_64.whl (65 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->openai)\n",
      "  Obtaining dependency information for frozenlist>=1.1.1 from https://files.pythonhosted.org/packages/27/e9/d149326cbcf9420c1e87c0bc2f956c9920638f2f78a9ca2384dac98a8354/frozenlist-1.4.0-cp39-cp39-macosx_10_9_x86_64.whl.metadata\n",
      "  Using cached frozenlist-1.4.0-cp39-cp39-macosx_10_9_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->openai)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Using cached aiohttp-3.8.5-cp39-cp39-macosx_10_9_x86_64.whl (368 kB)\n",
      "Downloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Using cached certifi-2023.7.22-py3-none-any.whl (158 kB)\n",
      "Using cached charset_normalizer-3.2.0-cp39-cp39-macosx_10_9_x86_64.whl (126 kB)\n",
      "Using cached frozenlist-1.4.0-cp39-cp39-macosx_10_9_x86_64.whl (47 kB)\n",
      "Using cached urllib3-2.0.5-py3-none-any.whl (123 kB)\n",
      "Installing collected packages: urllib3, tqdm, multidict, idna, frozenlist, charset-normalizer, certifi, attrs, async-timeout, yarl, requests, aiosignal, aiohttp, openai\n",
      "Successfully installed aiohttp-3.8.5 aiosignal-1.3.1 async-timeout-4.0.3 attrs-23.1.0 certifi-2023.7.22 charset-normalizer-3.2.0 frozenlist-1.4.0 idna-3.4 multidict-6.0.4 openai-0.28.0 requests-2.31.0 tqdm-4.66.1 urllib3-2.0.5 yarl-1.9.2\n"
     ]
    }
   ],
   "source": [
    "# !pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# CREDENTIALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credenciales API_KEYS\n",
    "with open('../input_data/openai.json', 'r', encoding='utf-8') as archivo:\n",
    "    openai_json = json.load(archivo)\n",
    "with open('../input_data/config.json', 'r', encoding='utf-8') as archivo:\n",
    "    config_json = json.load(archivo)\n",
    "OPENAI_API_KEY = config_json['OPENAI_API_KEY']\n",
    "OPENAI_PROMPT_FEEDBACK = openai_json['OPENAI_PROMPT_FEEDBACK']   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# SENTIMENT ANALYSIS MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": OPENAI_PROMPT_FEEDBACK\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      # \"content\": \"El evento ha sido magnífico. Pero el interlocutor hablaba muy bajito. Eso sí, las instalaciones son magníficas. Por cierto, ¿cuántos años tiene la ponente número 2?\"\n",
    "      \"content\": '[ \"El evento de ha sido muy bueno\", \" El interlocutor se ha explayado perfectamente, ha sido muy clarificador escucharle\", \" ha sido motivador\", \" Les ruego me envien un email a \" ]'\n",
    "    }\n",
    "  ],\n",
    "  temperature=0,\n",
    "  max_tokens=256,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-80It2ehyDvBNNexAgKGrej6hj1sEF at 0x10f7c0e00> JSON: {\n",
       "  \"id\": \"chatcmpl-80It2ehyDvBNNexAgKGrej6hj1sEF\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"created\": 1695083292,\n",
       "  \"model\": \"gpt-3.5-turbo-0613\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"role\": \"assistant\",\n",
       "        \"content\": \"{\\n  \\\"feedback_1\\\": 1,\\n  \\\"feedback_2\\\": 1,\\n  \\\"feedback_3\\\": 1,\\n  \\\"feedback_4\\\": 0\\n}\"\n",
       "      },\n",
       "      \"finish_reason\": \"stop\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 148,\n",
       "    \"completion_tokens\": 38,\n",
       "    \"total_tokens\": 186\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feedback_1': 1, 'feedback_2': 1, 'feedback_3': 1, 'feedback_4': 0}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = response['choices'][0]['message']['content']\n",
    "data = data.replace('{', '').replace('}', '').replace(',', '').replace('\"', '').strip().split('\\n')\n",
    "dict_data = {}\n",
    "for n in data:\n",
    "    letter = n.split(':')\n",
    "    key, value = letter[0], letter[1]\n",
    "    # print(key.strip(), value.strip())\n",
    "    dict_data[key.strip()] = int(value.strip())\n",
    "\n",
    "dict_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence_1': -1, 'sentence_2': -1}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = response['choices'][0]['message']['content']\n",
    "data = data.replace('{', '').replace('}', '').replace(',', '').replace('\"', '').strip().split('\\n')\n",
    "dict_data = {}\n",
    "for item in data:\n",
    "    prov = item.strip().split(':')\n",
    "    key, value = prov[0], prov[1]\n",
    "    dict_data[key] = int(value)\n",
    "\n",
    "dict_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "185"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usage = response['usage']\n",
    "usage['total_tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feedback_1': 1,\n",
       " 'feedback_2': 1,\n",
       " 'feedback_3': 1,\n",
       " 'feedback_4': 0,\n",
       " 'prompt_tokens': 148,\n",
       " 'completion_tokens': 38,\n",
       " 'total_tokens': 186}"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usage = response['usage']\n",
    "\n",
    "for key, value in usage.items():\n",
    "    dict_data[key] = value\n",
    "\n",
    "dict_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# COVER IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'yatch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Image.create(\n",
    "  prompt=f'Cream-coloured {text} in cartoon style with irregularly thick lines and without landscape.',\n",
    "  n=1,\n",
    "  size=\"1024x1024\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject at 0x10f7ba0e0> JSON: {\n",
       "  \"created\": 1695117353,\n",
       "  \"data\": [\n",
       "    {\n",
       "      \"url\": \"https://oaidalleapiprodscus.blob.core.windows.net/private/org-Z8UrHFMPw0zyGUrm6TeVKpWP/user-gKdhCWQSrWOAUpdulrHBsUzI/img-cHElInUqLOl56DgeSVxeJix6.png?st=2023-09-19T08%3A55%3A53Z&se=2023-09-19T10%3A55%3A53Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-09-18T21%3A43%3A52Z&ske=2023-09-19T21%3A43%3A52Z&sks=b&skv=2021-08-06&sig=IwkKrU7iyBUVmvESf6CtYaXQzqhKOlpx0mgaGh4F0Ps%3D\"\n",
       "    }\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://oaidalleapiprodscus.blob.core.windows.net/private/org-Z8UrHFMPw0zyGUrm6TeVKpWP/user-gKdhCWQSrWOAUpdulrHBsUzI/img-jQcDCBBV8WjUj47hkCkyuqBZ.png?st=2023-09-19T08%3A01%3A49Z&se=2023-09-19T10%3A01%3A49Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-09-18T21%3A53%3A16Z&ske=2023-09-19T21%3A53%3A16Z&sks=b&skv=2021-08-06&sig=LTgmcd3Sjtz8I5p2gO6QeNd%2B2cF8mwBjkjde0rFu8O0%3D'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ejemplo 1\n",
    "\n",
    "response['data'][0]['url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://oaidalleapiprodscus.blob.core.windows.net/private/org-Z8UrHFMPw0zyGUrm6TeVKpWP/user-gKdhCWQSrWOAUpdulrHBsUzI/img-cHElInUqLOl56DgeSVxeJix6.png?st=2023-09-19T08%3A55%3A53Z&se=2023-09-19T10%3A55%3A53Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-09-18T21%3A43%3A52Z&ske=2023-09-19T21%3A43%3A52Z&sks=b&skv=2021-08-06&sig=IwkKrU7iyBUVmvESf6CtYaXQzqhKOlpx0mgaGh4F0Ps%3D'"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ejmeplo 2\n",
    "\n",
    "response['data'][0]['url']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thebridge_desafio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
